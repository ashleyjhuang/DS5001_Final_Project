{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Notebook\n",
    "\n",
    "DS 5001 Exploratory Text Analytics | Spring 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata\n",
    "\n",
    "- Full Name: Ashley Huang\n",
    "- Userid: ajh5ae\n",
    "- GitHub Repo URL: https://github.com/ashleyjhuang/DS5001_Final_Project/tree/main\n",
    "- UVA Box URL: https://virginia.app.box.com/folder/261887899135"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The goal of the final project is for you to create a **digital analytical edition** of a corpus using the tools, practices, and perspectives youâ€™ve learning in this course. You will select a corpus that has already been digitized and transcribed, parse that into an F-compliant set of tables, and then generate and visualize the results of a series of fitted models. You will also draw some tentative conclusions regarding the linguistic, cultural, psychological, or historical features represented by your corpus. The point of the exercise is to have you work with a corpus through the entire pipeline from ingestion to interpretation. \n",
    "\n",
    "Specifically, you will acquire a collection of long-form texts and perform the following operations:\n",
    "\n",
    "- **Convert** the collection from their source formats (F0) into a set of tables that conform to the Standard Text Analytic Data Model (F2).\n",
    "- **Annotate** these tables with statistical and linguistic features using NLP libraries such as NLTK (F3).\n",
    "- **Produce** a vector representation of the corpus to generate TFIDF values to add to the TOKEN (aka CORPUS) and VOCAB tables (F4).\n",
    "- **Model** the annotated and vectorized model with tables and features derived from the application of unsupervised methods, including PCA, LDA, and word2vec (F5).\n",
    "- **Explore** your results using statistical and visual methods.\n",
    "- **Present** conclusions about patterns observed in the corpus by means of these operations.\n",
    "\n",
    "When you are finished, you will make the results of your work available in GitHub (for code) and UVA Box (for data). You will submit to Gradescope (via Canvas) a PDF version of a Jupyter notebook that contains the information listed below.\n",
    "\n",
    "# Some Details\n",
    "\n",
    "- Please fill out your answers in each task below by editing the markdown cell. \n",
    "- Replace text that asks you to insert something with the thing, i.e. replace `(INSERT IMAGE HERE)` with an image element, e.g. `![](image.png)`.\n",
    "- For URLs, just paste the raw URL directly into the text area. Don't worry about providing link labels using `[label](link)`.\n",
    "- Please do not alter the structure of the document or cell, i.e. the bulleted lists. \n",
    "- You may add explanatory paragraphs below the bulleted lists.\n",
    "- Please name your tables as they are named in each task below.\n",
    "- Tasks are indicated by headers with point values in parentheses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Description (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source materials are sourced from the Project Gutenberg. The source materials are long-form books written by Lewis Caroll and Fyodor Dostoevsky throughout their their lifetime. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Source Features (1)\n",
    "\n",
    "Add values for the following items. (Do this for all following bulleted lists.)\n",
    "\n",
    "- Source URL: \n",
    "1. https://www.gutenberg.org/cache/epub/11/pg11.txt (Alice in Wonderland)\n",
    "2. https://www.gutenberg.org/files/29888/29888-h/29888-h.htm (Hunting of the Snark)\n",
    "3. https://www.gutenberg.org/files/48795/48795-h/48795-h.htm (Slvie and Bruno pt 2.)\n",
    "4. https://www.gutenberg.org/files/48630/48630-h/48630-h.htm (Syvie and Bruno)\n",
    "5. https://www.gutenberg.org/files/29042/29042-h/29042-h.htm (A Tangled Tale)\n",
    "6. https://www.gutenberg.org/files/55040/55040-h/55040-h.htm (The Nursery)\n",
    "7. https://www.gutenberg.org/cache/epub/12/pg12.txt (Through the Looking Glass)\n",
    "8. https://www.gutenberg.org/cache/epub/2554/pg2554.txt (Crime and Punishment)\n",
    "9. https://www.gutenberg.org/cache/epub/28054/pg28054.txt (The Brothers Karamazov)\n",
    "10. https://www.gutenberg.org/cache/epub/8117/pg8117.txt (The Devils)\n",
    "\n",
    "- UVA Box URL: https://virginia.app.box.com/folder/261894445533\n",
    "- Number of raw documents: 10 documents\n",
    "- Total size of raw documents (e.g. in MB): (170 + 53.6 + 456 + 328 + 173 + 67.2 + 191 + 1140 + 1940 + 1410) 5928.8 Mb\n",
    "- File format(s), e.g. XML, plaintext, etc.: TXT files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Source Document Structure (1)\n",
    "\n",
    "This is a corpus of different books written by Lewis Carroll and Fyodor Dostoevsky. I chose these two authors since they are some of the most famous authors of the 19th century, and their works overlap chronologically. The books in the corpus have a list of chapters names, followed by a set of content chapters (some with chapter titles, some without), and an ending. Additionally, some of the books written by Lewis Carroll have a preface section before the chapter list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsed and Annotated Data\n",
    "\n",
    "Parse the raw data into the three core tables of your addition: the `LIB`, `CORPUS`, and `VOCAB` tables.\n",
    "\n",
    "These tables will be stored as CSV files with header rows.\n",
    "\n",
    "You may consider using `|` as a delimitter.\n",
    "\n",
    "Provide the following information for each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIB (2)\n",
    "\n",
    "The source documents the corpus comprises. These may be books, plays, newspaper articles, abstracts, blog posts, etc. \n",
    "\n",
    "Note that these are *not* documents in the sense used to describe a bag-of-words representation of a text, e.g. chapter.\n",
    "\n",
    "- UVA Box URL: https://virginia.app.box.com/file/1520175318622\n",
    "- GitHub URL for notebook used to create: https://github.com/ashleyjhuang/DS5001_Final_Project\n",
    "- Delimitter: None\n",
    "- Number of observations: 10 observations\n",
    "- List of features, including at least three that may be used for model summarization (e.g. date, author, etc.): \n",
    "\n",
    "[book_id, source_file_path, popularity, era, author_id, title, chap_regex, book_len, n_chaps]\n",
    "\n",
    "- Average length of each document in characters: \n",
    "\n",
    "[Alice in Wonderland (26559), Hunting of the Snark (5035), Slyvie and Bruno pt 2 (71210), Slyvie and Bruno (65692), A Tangled Tale (27864), The Nursery (8342), Through The Looking Glass (29462), Crime and Punishment (204192), The Brothers Karamazov (349447), The Devils (255110)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORPUS (2)\n",
    "\n",
    "The sequence of word tokens in the corpus, indexed by their location in the corpus and document structures.\n",
    "\n",
    "- UVA Box URL: https://virginia.app.box.com/file/1520175066765\n",
    "- GitHub URL for notebook used to create: https://github.com/ashleyjhuang/DS5001_Final_Project\n",
    "- Delimitter: None\n",
    "- Number of observations Between (should be >= 500,000 and <= 2,000,000 observations.): 1042819\n",
    "- OHCO Structure (as delimitted column names): ['book_id', 'chap_num', 'para_num', 'sent_num', 'token_num']\n",
    "- Columns (as delimitted column names, including `token_str`, `term_str`, `pos`, and `pos_group`): \n",
    "['book_id', 'chap_num', 'para_num', 'sent_num', 'token_num', 'pos_tuple', 'pos', 'token_str', 'term_str', 'pos_group']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VOCAB (2)\n",
    "\n",
    "The unique word types (terms) in the corpus.\n",
    "\n",
    "- UVA Box URL: https://virginia.app.box.com/file/1520169789259\n",
    "- GitHub URL for notebook used to create: https://github.com/ashleyjhuang/DS5001_Final_Project\n",
    "- Delimitter: None\n",
    "- Number of observations: 24344\n",
    "- Columns (as delimitted names, including `n`, `p`', `i`, `dfidf`, `porter_stem`, `max_pos` and `max_pos_group`, `stop`): \n",
    "\n",
    "['n', 'n_chars', 'p', 'i', 'max_pos', 'max_pos_group', 'n_pos_group','cat_pos_group', 'n_pos', 'cat_pos', 'stop', 'stem_porter',\n",
    "'stem_snowball', 'stem_lancaster', 'dfidf', 'mean_tfidf', 'df']\n",
    "\n",
    "- Note: Your VOCAB may contain ngrams. If so, add a feature for `ngram_length`.\n",
    "- List the top 20 significant words in the corpus by DFIDF.\n",
    "\n",
    "['rushed', 'laugh', 'laughing', 'roubles', 'object', 'youd', 'surprised', 'ground', 'fell', 'friends', 'haste', 'says', 'nonsense', 'soul', 'espicially', 'wonder', 'position', 'person', 'carried', 'hair'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derived Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW (3)\n",
    "\n",
    "A bag-of-words representation of the CORPUS.\n",
    "\n",
    "- UVA Box URL: https://virginia.app.box.com/file/1520175610892\n",
    "- GitHub URL for notebook used to create: https://github.com/ashleyjhuang/DS5001_Final_Project\n",
    "- Delimitter: None\n",
    "- Bag (expressed in terms of OHCO levels): bag = ['book_id', 'chap_id']\n",
    "- Number of observations: 250288\n",
    "- Columns (as delimitted names, including `n`, `tfidf`): ['book_id', 'chap_id', 'term_str', 'n']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DTM (3)\n",
    "\n",
    "A represenation of the BOW as a sparse count matrix.\n",
    "\n",
    "- UVA Box URL: https://virginia.app.box.com/file/1520171371081\n",
    "- UVA Box URL of BOW used to generate (if applicable): https://virginia.app.box.com/file/1520175610892\n",
    "- GitHub URL for notebook used to create: https://github.com/ashleyjhuang/DS5001_Final_Project\n",
    "- Delimitter: None\n",
    "- Bag (expressed in terms of OHCO levels): bag = ['book_id', 'chap_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF (3)\n",
    "\n",
    "A Document-Term matrix with TFIDF values.\n",
    "\n",
    "- UVA Box URL: https://virginia.app.box.com/file/1520180248225\n",
    "- UVA Box URL of DTM or BOW used to create: https://virginia.app.box.com/file/1520175610892\n",
    "- GitHub URL for notebook used to create: https://github.com/ashleyjhuang/DS5001_Final_Project\n",
    "- Delimitter: None\n",
    "- Description of TFIDIF formula ($\\LaTeX$ OK):  TF = (DTCM.T / DTCM.T.sum()).T, IDF = np.log2(N_docs/DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reduced and Normalized TFIDF_L2 (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "A Document-Term matrix with L2 normalized TFIDF values.\n",
    "\n",
    "- UVA Box URL: https://virginia.app.box.com/file/1520178479327\n",
    "- UVA Box URL of source TFIDF table: https://virginia.app.box.com/file/1520180248225\n",
    "- GitHub URL for notebook used to create: https://github.com/ashleyjhuang/DS5001_Final_Project\n",
    "- Delimitter: None\n",
    "- Number of features (i.e. significant words): 1000\n",
    "- Principle of significant word selection: Ecludiean (M.apply(lambda x: x / norm(x), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Components (4)\n",
    "\n",
    "- UVA Box URL: https://virginia.app.box.com/file/1520171077409\n",
    "- UVA Box URL of the source TFIDF_L2 table: https://virginia.app.box.com/file/1520180248225\n",
    "- GitHub URL for notebook used to create: https://github.com/ashleyjhuang/DS5001_Final_Project\n",
    "- Delimitter: None\n",
    "- Number of components: 9\n",
    "- Library used to generate: TFIDF (and TFIDF[VIDX])\n",
    "- Top 5 positive terms for first component: bruno, sylvie, lady, replied, song\t\n",
    "- Top 5 negative terms for second component: alyosha, ivan, mitya, pyotr, dmitri\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PCA DCM (4)\n",
    "\n",
    "The document-component matrix generated.\n",
    "\n",
    "- UVA Box URL: https://virginia.app.box.com/file/1520171922327\n",
    "- GitHub URL for notebook used to create: https://github.com/ashleyjhuang/DS5001_Final_Project\n",
    "- Delimitter: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PCA Loadings (4)\n",
    "\n",
    "The component-term matrix generated.\n",
    "\n",
    "- UVA Box URL: https://virginia.app.box.com/file/1520175151046\n",
    "- GitHub URL for notebook used to create: https://github.com/ashleyjhuang/DS5001_Final_Project\n",
    "- Delimitter: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Visualization 1 (4)\n",
    "\n",
    "Include a scatterplot of documents in the space created by the first two components.\n",
    "\n",
    "Color the points based on a metadata feature associated with the documents.\n",
    "\n",
    "Also include a scatterplot of the loadings for the same two components. (This does not need a feature mapped onto color.)\n",
    "\n",
    "Scatterplot of documents created by the first two components:\n",
    "\n",
    "![](pca_dcm_v1.png)\n",
    "\n",
    "Scatterplot of loadings created by the first two components:\n",
    "\n",
    "![](pca_loadings_v1.png)\n",
    "\n",
    "Briefly describe the nature of the polarity you see in the first component:\n",
    "\n",
    "This visualization shows the scatterplot of the first two component loadings. We can see from the scatterplot that the late group of the era category has the most diverse/least similiar features, compared to other groups. This suggests that they are more differences within books published in the late writing era of both authors. We also see clustering of the other era categories in the scatterplot, which indicates similiarity amongst them. Finally, the two long \"arms\" in the dataset are comprised of three specific books: Slyvie and Bruno & Slyvie and Bruno (right arm) and Crime and Punishment (left arm). The positioning of these two documents (nearly orthogonal) suggests possible similarity between the two documents. The orthogonal structure (unlike the point clustering for similarity) could arise due to different words used in each document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Visualization 2 (4)\n",
    "\n",
    "Include a scatterplot of documents in the space created by the second two components.\n",
    "\n",
    "Color the points based on a metadata feature associated with the documents.\n",
    "\n",
    "Also include a scatterplot of the loadings for the same two components. (This does not need a feature mapped onto color.)\n",
    "\n",
    "Scatterplot of documents in the space created by the second two components:\n",
    "\n",
    "![](pca_dcm_v2.png)\n",
    "\n",
    "Scatterplot of loadings for the second two components:\n",
    "\n",
    "![](pca_loadings_v2.png)\n",
    "\n",
    "Briefly describe the nature of the polarity you see in the second component:\n",
    "\n",
    "In the second PCA documents scatterplot, we see similiar trends as the first scatterplot of the documents. The late era has a greater variance than the other genres, across the x-axis (PCA component 2). This suggest higher intra-group variance/dis-similarity than other eras. However, across the PCA component 2, we see that middle era also displays higher variance compared to the previous visualization. There seems to some clustering/similiarity in the early era documents, while the middle era documents are more dispersed/different. \n",
    "\n",
    "In the second PCA loadings scatterplot, there generally seems to be a balanced amount of words that contribute positively (positive loading values) and negatively (negative loading values) toward PCA component 2 since most of the values are centered around zero. However, we can see that there are some outliers: mitya has a relatively high negative contribution to PC 2 and Alyosha has a relatively high positiev contribution to PC2. This is also the case with PC 3, to less of an extent. We only see one stark outlier (the term pyotr, which very negatively influences PC3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LDA TOPIC (4)\n",
    "\n",
    "- UVA Box URL: https://virginia.app.box.com/file/1520172138157\n",
    "- UVA Box URL of count matrix used to create: Not Applicable\n",
    "- GitHub URL for notebook used to create:\n",
    "- Delimitter: None\n",
    "- Libary used to compute: LatentDirichletAllocation\n",
    "- A description of any filtering, e.g. POS (Nouns and Verbs only): No filtering\n",
    "- Number of components: 20\n",
    "- Any other parameters used: None\n",
    "- Top 5 words and best-guess labels for topic five topics by mean document weight:\n",
    "  - T00: time man way room face\n",
    "  - T01: man time money yes moment\n",
    "  - T02: time man course people money\n",
    "  - T03: gentlemen prosecutor man door time\n",
    "  - T04: man people men elder life"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LDA THETA (4)\n",
    "\n",
    "- UVA Box URL: https://virginia.app.box.com/file/1520176213597\n",
    "- GitHub URL for notebook used to create:\n",
    "- Delimitter: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LDA PHI (4)\n",
    "\n",
    "- UVA Box URL: https://virginia.app.box.com/file/1520170144260\n",
    "- GitHub URL for notebook used to create:\n",
    "- Delimitter: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA + PCA Visualization (4)\n",
    "\n",
    "Apply PCA to the PHI table and plot the topics in the space opened by the first two components.\n",
    "\n",
    "Size the points based on the mean document weight of each topic (using the THETA table).\n",
    "\n",
    "Provide a brief interpretation of what you see.\n",
    "\n",
    "![](LDA_PCA_plot.png)\n",
    "\n",
    "Generally, looking at the scatterplot, we don't see immediate clusters of data points or orthogonal structures, which suggests that the probability distributions of words in each topic id are not similiar across the two principal components. Looking at the topic space of the first two components of the PCA PHI table, we can see that across the first principal component (PC0), there are more topics that negatively influences the principal component, which means that the those topics are negatively correlated with the principle component. However, looking at second principal component (PC1), the majority of data points have positive values, which means that substaintially more topics have a positive correlation with the principal component. This dichotomy between the principal components is interesting to see and might be attributed to differences between books in the corpus. \n",
    "\n",
    "In the PCA loadings scatterplot, most of the points are centered around zero for the first principal component (PC0). However, we can see that the data points leave a negative tail. This means that there are a number of words that have a negative influence or have a negative correlation with the first principal component. Some examples of these words are Ivan and Mitya. There are also some positive outliers across the first component. Words like Bruno and Slyvie positive contribute (have a positive correlation) to the first principal component. These general outlying trends are also seen across the second principal component (PC1).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment VOCAB_SENT (4)\n",
    "\n",
    "Sentiment values associated with a subset of the VOCAB from a curated sentiment lexicon.\n",
    "\n",
    "- UVA Box URL: https://virginia.app.box.com/file/1520171046474\n",
    "- UVA Box URL for source lexicon: https://virginia.app.box.com/file/1520193278263 \n",
    "- GitHub URL for notebook used to create: https://github.com/ashleyjhuang/DS5001_Final_Project\n",
    "- Delimitter: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sentiment BOW_SENT (4)\n",
    "\n",
    "Sentiment values from VOCAB_SENT mapped onto BOW.\n",
    "\n",
    "- UVA Box URL: https://virginia.app.box.com/file/1520180439984\n",
    "- GitHub URL for notebook used to create: https://github.com/ashleyjhuang/DS5001_Final_Project\n",
    "- Delimitter: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment DOC_SENT (4)\n",
    "\n",
    "Computed sentiment per bag computed from BOW_SENT.\n",
    "\n",
    "- UVA Box URL: https://virginia.app.box.com/file/1520169645317\n",
    "- GitHub URL for notebook used to create: https://github.com/ashleyjhuang/DS5001_Final_Project\n",
    "- Delimitter: None\n",
    "- Document bag expressed in terms of OHCO levels: ['book_id', 'chap_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Plot (4)\n",
    "\n",
    "Plot sentiment over some metric space, such as time.\n",
    "\n",
    "If you don't have a metric metadata features, plot sentiment over a feature of your choice.\n",
    "\n",
    "You may use a bar chart or a line graph.\n",
    "\n",
    "![](Sentiment_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VOCAB_W2V (4)\n",
    "\n",
    "A table of word2vec features associated with terms in the VOCAB table.\n",
    "\n",
    "- UVA Box URL: https://virginia.app.box.com/file/1520176271146\n",
    "- GitHub URL for notebook used to create: https://github.com/ashleyjhuang/DS5001_Final_Project\n",
    "- Delimitter: None\n",
    "- Document bag expressed in terms of OHCO levels: ['book_id', 'chap_id', 'para_num']\n",
    "- Number of features generated: 256\n",
    "- The library used to generate the embeddings: CORPUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec tSNE Plot (4)\n",
    "\n",
    "Plot word embedding featues in two-dimensions using t-SNE.\n",
    "\n",
    "Describe a cluster in the plot that captures your attention.\n",
    "\n",
    "![](TNSE_plot.png)\n",
    "\n",
    "![](TNSE_plot2.png)\n",
    "\n",
    "A cluster in the t-SNE plot that really captures my attention is the character-cluster, as I like to call it. This cluster of points, located at the top of the image, comprises various names of characters that appear throughout the corpus. This cluster in particular caught my eye because of massive number of data points it contains (i.e. the cluster looked very concentrated and dark), and its observable separation from other points. These characteristics made me curious about what the cluster may mean and relationships in the cluster. One thing I noticed about this cluster was that it comprised mostly russian names (e.g. pavlovitch), which could be a nod to the various characters mentioned in dostoevsky's novels in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Riffs\n",
    "\n",
    "Provde at least three visualizations that combine the preceding model data in interesting ways.\n",
    "\n",
    "These should provide insight into how features in the LIB table are related. \n",
    "\n",
    "The nature of this relationship is left open to you -- it may be correlation, or mutual information, or something less well defined. \n",
    "\n",
    "In doing so, consider the following visualization types:\n",
    "\n",
    "- Hierarchical cluster diagrams\n",
    "- Heatmaps\n",
    "- Scatter plots\n",
    "- KDE plots\n",
    "- Dispersion plots\n",
    "- t-SNE plots\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Riff 1 (5)\n",
    "\n",
    "![](Riff_1a.png)\n",
    "\n",
    "![](Riff_1b.png)\n",
    "\n",
    "![](Riff_1c.png)\n",
    "\n",
    "![](Riff_1d.png)\n",
    "\n",
    "![](Riff_1e.png)\n",
    "\n",
    "The first riff shows the hierarchial models, depicting the similiarity of books in the corps. Looking at these hierarchial models, we see that the different linkage methods group the different books in the corpus differently. All but one of the different linkage methods grouped the documents in the corpus along their respective author (e.g. the different books within a cluster were from one author). This might imply distinctive writing styles between the two authors. The only method that didn't group documents along author was the jaccard-weighted model. The jaccard-weighted method also seems to be the least sensitive since it picked up only one cluster, where other models picked up three different clusters. The other models clustered generally how we would expect it to. For instance, all of them grouped Slyvie and Bruno and Slyvie and Bruno Pt 2 together. This makes sense since they're a duology, therefore they would exihibit high levels of similiarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Riff 2 (5)\n",
    "\n",
    "![](Riff_2.png)\n",
    "\n",
    "The second riff shows a heat-map of the correlation between the different books in the corpus. This is computed from the correlation matrix of the TFIDF table (where the bag is set to the book_id) transpose. We specifically looked the the kendall-correlation since it is more lenient about variable distributions. Looking at this heat-map, we can see similiar aspects that are shared with the hierarchial models. For instance, two of the most highly correlated books are book_id 1 (Alice in Wonderland) and book_id 7 (Through the Looking Glass). This is also seen in the hierarhcial models, where all the methods except jaccard-weighted grouped them together too. In the heat-map, book_id 8 (Crime and Punishment) and book_id 10 (The Devils) also had higher correlation values. This is also expected since Crime and Punishment and The Devils are unanimously grouped together across all hierarhcial model linkage methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Riff 3 (5)\n",
    "\n",
    "![](Riff_3a.png)\n",
    "\n",
    "The third riff shows a set of heat-map of the correlation between topic models for Crime and Punishment. I wanted to look at the models for one book, rather than the whole corpus, for more focused/interpretable topics. I specifically wanted to look at Crime and Punishment since it is the lengthiest book in the corpus. This first heat map shows the correlation between one topic model with itself for Crime and Punishment. There's not that much similiarity among the topics of the model (not a lot of red squares seen). We see that the diagonal has the highest similiarity, which makes sense since topics that comprise the diagonal are identical. Beyond the diagonal, there is a lot less similiarity. Although, there seems to be some similiarity among topic 0 and topic 3 of the model. Next, we will see if there is more similiarity across topics from two different models.\n",
    "\n",
    "![](Riff_3b.png)\n",
    "\n",
    "Looking at the heat-map, there is still not a lot of similiarity between the topics generated by the two models. However, it seems that there is more similiarity among the topics generated by two different models (more red squares), which is inteesting since it seems counter-intuitive that topics from two different models would have more similiarity than topics from within one model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation (4)\n",
    "\n",
    "Describe something interesting about your corpus that you discovered during the process of completing this assignment.\n",
    "\n",
    "At a minumum, use 250 words, but you may use more. You may also add images if you'd like.\n",
    "\n",
    "One interesting thing that I've learned about my corpus while doing this assignment is that children read depressing books in the 19th century. I was interested in the differences in sentiments of each of the books in the corpus. I thought that it would be interesting since the primary audience/primary genres of the authors are quite different. Lewis Carroll mostly wrote children's stories that had a lot of elements of fantasy, playfulness, and imagination. Therefore, there should be more words that have positive connotations and words that have a high positive connotation values. \n",
    "\n",
    "Fyodor Dostoevsky mostly wrote books that explored darker and heavier themes such as corruption, murder, betrayal, etc (e.g. The Devils). Therefore, he had an older audience that were familiar with these themes. Therefore, Dostoevsky's books should have more words with negative connotations and more words with high negative connotation values. \n",
    "\n",
    "To see the trends in the sentiment analysis of each book in the corpus, I plotted a bar-plot looking at the emotions of each book (calculated from an external emotion lexicon and weighted by the average TFIDF). \n",
    "\n",
    "![](Interpretation_1.png)\n",
    "\n",
    "Looking at the bar-plot, I focused specifically on negative and positive sentiment because the external sentiment lexicon had a wide range of emotional representation (e.g. anger, disgust, fear, etc.), so I thought positive/negative numerical values would succinctly summarize the general sentiment without going into very granular details. We see that Lewis Carroll's books tend to have higher values for the positive category than Dostoevsky's books, which is not surprising given his writing genre and audience. However, many of Lewis Carroll's books had substantially higher negative sentiment values, i.e. many of Lewis Carroll's children's books essentially \"out-negatived\" Dostovesky's books, which was really surprising. \n",
    "\n",
    "One possible explanation lies in the external sentiment lexicon. It is possible that using a different lexicon might change these trends. However, it is unlikely to completely change the trends that we see. Instead, it is likely to shift, rather than completely transform, the sentiment trends present in the bar-plot.\n",
    "\n",
    "A second explanation lies in language itself. Dostoevsky was a Russian author, who wrote his books in Russian. The source data that is used to derive the sentiment bar-plots is in English (his work was translated to English). Therefore, it is possible that there are Russian words lost/altered in translation due to the absence of equivalent English words. Therefore, the emotional weight behind some words may not be completely accounted for in the sentiment analysis. This might be a reason why we see the trends in the sentiment bar-plot. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
